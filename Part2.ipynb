{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e21313ea",
   "metadata": {},
   "source": [
    "### PART 02. 프롬프트와 출력 파서\n",
    "\n",
    "#### Chapter5. 프롬프트\n",
    "\n",
    "#### 1. 프롬프트 탬플릿 만들기\n",
    "\n",
    "##### - 프롬프트 탬플릿의 구조\n",
    "- 지시 사항(Instruction), 질문(Question), 문맥(Context)로 구성\n",
    "\n",
    "##### - PromptTemplate 객체\n",
    "- 프롬프트 템플릿 객체\n",
    "\n",
    "- `template` : 프롬프트 문자열(지시사항, 질문, 문맥 등 지정)\n",
    "\n",
    "- `input_variables` : 입력해야할 변수 목록(명), LangChain이 자동 추출(from_template()로)\n",
    "\n",
    "- `partial_variables` : 사전 입력해둔 변수 목록(명)\n",
    "\n",
    "##### - 프롬프트 템플릿 만드는 방법\n",
    "방법 1. from_template() 메서드를 사용하여 PromptTemplate 객체 생성\n",
    "\n",
    "- 치환될 변수를 `placeholder`로 생성하여 `{ }`로 묶어서 넣을 문자열 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e39b6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "#!pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH02-Prompt\")\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a99b42",
   "metadata": {},
   "source": [
    "`template` 매개변수에 값을 치환하여 생성(렌더링)하는 방법\n",
    "\n",
    "- format 메서드 사용(수동 렌더링) : 사용자가 직접 PromptTemplate의 변수를 치환하여 문자열 프롬프트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b791aa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# template 정의. {country}는 변수로, 이후에 값이 들어갈 자리를 의미\n",
    "template = \"{country}의 수도는 어디인가요?\" # country는 단순 변수명\n",
    "\n",
    "# from_template 메서드로 PromptTemplate 객체 생성\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# 단순 prompt 생성, format 메서드로 변수에 값을 치환\n",
    "# 문자열 프롬프트 반환(PromptTemplate 객체 X)\n",
    "prompt = prompt.format(country=\"대한민국\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885ba744",
   "metadata": {},
   "source": [
    "- chain 생성 후 invoke 메서드 사용(자동 렌더링)\n",
    " : LangChain이 입력 값을 받아 PromptTemplate 내부에서 format 메서드 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b385de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# template 정의. {country}는 변수로, 이후에 값이 들어갈 자리를 의미\n",
    "template = \"{country}의 수도는 어디인가요?\" # country는 단순 변수명\n",
    "\n",
    "# from_template 메서드로 PromptTemplate 객체 생성\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# chain 생성\n",
    "chain = prompt | llm\n",
    "\n",
    "# country 변수에 입력된 값이 자동으로 치환되어 수행됨\n",
    "# ChatOpenAI는 메시지 객체(AIMessage)를 반환하여 content 속성으로 접근\n",
    "chain.invoke(\"대한민국\").content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347fa71f",
   "metadata": {},
   "source": [
    "\n",
    "방법 2. PromptTemplate 객체 생성과 동시에 prompt 생성\n",
    "- `template`과 `input_variables` 매개변수 직접 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcec1fac",
   "metadata": {},
   "source": [
    "- `template`이 받는 인자가 1개인 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155240e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# template 정의\n",
    "template = \"{country}의 수도는 어디인가요?\"\n",
    "\n",
    "# PromptTemplate 객체를 활용하여 prompt_template 생성\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"country\"], # input_variables값을 직접 지정, country 변수가 아닐 경우 error 발생\n",
    ")\n",
    "\n",
    "# prompt 생성\n",
    "prompt.format(country=\"대한민국\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9deae3",
   "metadata": {},
   "source": [
    "- `template`이 받는 인자가 여러개인 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4645823",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# template 정의\n",
    "template = \"{country1}과 {country2}의 수도는 각각 어디인가요?\"\n",
    "\n",
    "# PromptTemplate 객체를 활용하여 prompt_template 생성\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"country1\"],\n",
    "    partial_variables={\n",
    "        \"country2\": \"미국\"  # country2 값 미리 지정\n",
    "    },\n",
    ")\n",
    "\n",
    "prompt.format(country1=\"대한민국\")\n",
    "prompt_partial = prompt.partial(country2=\"캐나다\") # partial 메서드로 기존 PromptTemplate 객체를 복사하여 country2 값 변경\n",
    "prompt_partial.format(country1=\"대한민국\")\n",
    "\n",
    "chain = prompt_partial | llm\n",
    "\n",
    "chain.invoke(\"대한민국\").content\n",
    "chain.invoke({\"country1\": \"대한민국\", \"country2\": \"호주\"}).content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239e10e0",
   "metadata": {},
   "source": [
    "##### - 부분 변수 활용하기\n",
    ": 사용자 정의 함수를 통해 프롬프트의 일부를 미리 설정 ex) 현재 날짜 자동 출력\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f9e33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 오늘 날짜를 출력\n",
    "datetime.now().strftime(\"%B %d\")\n",
    "\n",
    "# 날짜를 반환하는 함수 정의\n",
    "def get_today():\n",
    "    return datetime.now().strftime(\"%B %d\")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"오늘의 날짜는 {today} 입니다. 오늘이 생일인 유명인 {n}명을 나열해 주세요. 생년월일을 표기해주세요.\",\n",
    "    input_variables=[\"n\"],\n",
    "    partial_variables={\n",
    "        \"today\": get_today  # today 함수 미리 지정\n",
    "    },\n",
    ")\n",
    "\n",
    "# prompt 생성\n",
    "prompt.format(n=3)\n",
    "\n",
    "# chain 생성\n",
    "chain = prompt | llm\n",
    "\n",
    "print(chain.invoke(3).content)\n",
    "print(chain.invoke({\"today\": \"Jan 02\", \"n\": 3}).content) # 각 매개변수 값을 직접 지정(today 함수 무시)\n",
    "# ChatModel(ChatOpenAI) 사용 시 반환되는 AIMessage 객체에서 content로 텍스트를 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043fbf33",
   "metadata": {},
   "source": [
    "##### - YAML 파일로 프롬프트 템플릿 로드하기\n",
    "\n",
    "YAML(YAML Ain’t Markup Language)\n",
    " : \n",
    "\n",
    " → load_prompt()로 YAML 파일 불러옴 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eee07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import load_prompt\n",
    "from langchain_teddynote.prompts import load_prompt\n",
    "\n",
    "prompt = load_prompt(\"prompts/fruit_color.yaml\", encoding=\"utf-8\")\n",
    "prompt.format(fruit=\"사과\") # 프롬프트에 값 치환\n",
    "\n",
    "prompt2 = load_prompt(\"prompts/capital.yaml\")\n",
    "print(prompt2.format(country=\"대한민국\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e763149",
   "metadata": {},
   "source": [
    "#### 2. ChatPromptTemplate\n",
    "\n",
    "##### - ChatPromptTemplate 정의\n",
    ": 여러 메시지를 조합하여 대화형 프롬프트를 정의하는 템플릿 객체\n",
    "\n",
    "→ 튜플 형식으로 `(role, message)`형태로 구성\n",
    "\n",
    "→ MessagePromptTemplate를 모아 프롬프트를 설계하고,\n",
    "실행 시 Message 객체로 변환하여 LLM에 전달\n",
    "\n",
    "##### - Role의 구성요소\n",
    "- `system` : 시스템 설정 메시지로 표현  \n",
    "\n",
    "  → 모델의 말투, 금지사항, 역할, 출력 형식 등 대화 전체에 적용되는 전역 지시사항을 정의\n",
    "\n",
    "  ex) 규칙, 페르소나, 금지사항 지정\n",
    "\n",
    "  → 프롬프트 설계 시 `SystemMessagePromptTemplate`, 실행 시 `SystemMessage`객체로 전환\n",
    "\n",
    "- `human` : 사용자 입력 메시지로 표현  \n",
    "\n",
    "  → 실제 사용자 발화 또는 대화 맥락을 구성하기 위한 사용자 메시지\n",
    "\n",
    "  → 프롬프트 설계 시 `HumanMessagePromptTemplate`, 실행 시 `HumanMessage`객체로 전환\n",
    "\n",
    "- `ai` : AI 응답 메시지 (`AIMessage` 객체)로 표현  \n",
    "\n",
    "  → 모델이 어떤 방식으로 응답해야 하는지를 보여주는 예시 메시지로 활용될 수 있으며, 응답 스타일·형식·톤을 유도하는 역할을 수행\n",
    "  \n",
    "  → 퓨샷(few-shot)학습 효과를 유도함\n",
    "\n",
    "  → 프롬프트 설계 시 `AIMessagePromptTemplate`, 실행 시 `AIMessage`객체로 전환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095762f2",
   "metadata": {},
   "source": [
    "##### - PromptTemplate과 ChatPromptTemplate의 차이점\n",
    "\n",
    "\n",
    "| 구분 | PromptTemplate      | ChatPromptTemplate    |\n",
    "|------------|---------------------|---------------|\n",
    "|  출력 결과   |  문자열(str)  | 메시지 리스트(list[Message])          |\n",
    "|  입력 구조   |  단일 텍스트   |   role 기반 메시지      |\n",
    "|  모델 대상   |  LLM / ChatModel   |   ChatModel 전용      |\n",
    "|  내부 표현   |  텍스트  |   System / Human / AI Message      |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa38086f",
   "metadata": {},
   "source": [
    "##### - ChatPromptTemplate을 만드는 방법\n",
    "\n",
    "- 방법 1. 단일 메시지\n",
    ": `from_template()` 사용 → 내부적으로 역할이 human인 HumanMessagePromptTemplate 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d871023f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_template(\"{country}의 수도는 어디인가요?\") \n",
    "chat_prompt.format(country=\"대한민국\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e7306d",
   "metadata": {},
   "source": [
    "- 방법 2. 여러 역할과 메시지\n",
    ": `from_messages()` 사용, `system`, `human`, `ai` 메시지 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f4eec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 방법 2: 여러 역할 및 메시지, from_messages 메서드 사용\n",
    "chat_template = ChatPromptTemplate.from_messages( \n",
    "    [\n",
    "        # role, message로 tuple 형태로 정의\n",
    "        (\"system\", \"당신은 친절한 AI 어시스턴트입니다. 당신의 이름은 {name} 입니다.\"),\n",
    "        (\"human\", \"반가워요!\"),\n",
    "        (\"ai\", \"안녕하세요! 무엇을 도와드릴까요?\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ") # name, user_input에 값이 없는 경우 error 발생"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f442f3",
   "metadata": {},
   "source": [
    "##### - ChatPromptTemplate 실행방법\n",
    "\n",
    "- 방법 1. `format_messages()`로 메시지 생성 후 LLM 호출(수동 렌더링)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f731c60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법 1. 메시지 생성 후 LLM 호출 \n",
    "messages = chat_template.format_messages(\n",
    "    name=\"테디\", user_input=\"당신의 이름은 무엇입니까?\"\n",
    ")\n",
    "llm.invoke(messages).content # LLM 호출, AIMessage 객체에서 content로 텍스트 추출(ChatModel이기 때문)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06a7a4e",
   "metadata": {},
   "source": [
    "\n",
    "- 방법 2. chain 생성 후 invoke 메서드 사용(자동 렌더링)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c011e93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법 2. 체인으로 invoke 메서드 사용하여 LLM 호출\n",
    "chain = chat_template | llm # chain 생성\n",
    "chain.invoke({\"name\": \"Teddy\", \"user_input\": \"당신의 이름은 무엇입니까?\"}).content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec21819",
   "metadata": {},
   "source": [
    "#### 3. MessagesPlaceholder\n",
    "\n",
    "##### - MessagesPlaceholder\n",
    " : `ChatPromptTemplate`을 구성요소(컴포넌트) 중 하나로, 여러 메시지(대화 기록)을 삽입하기 위함\n",
    " \n",
    " → `ChatPromptTemplate` 중간에 `MessagesPlaceholder` 삽입\n",
    "\n",
    " → 실행 시점, 대화 기록 개수, 대화 내용 등은 동적으로 삽입됨(실행 시 결정)\n",
    "\n",
    "##### - MessagesPlaceholder 객체\n",
    "\n",
    "- `variable_name` : 외부에서 전달받을 변수(명)\n",
    "\n",
    "- `optional` : 해당 변수가 리스트에 없는 경우 error 발생의 여부\n",
    "  - `optional = True` : 없는 경우 정상 실행\n",
    "\n",
    "  - `optional = False` : 없는 경우 error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6f980e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"당신은 요약 전문 AI 어시스턴트입니다. 당신의 임무는 주요 키워드로 대화를 요약하는 것입니다.\"), # system 메시지\n",
    "        MessagesPlaceholder(variable_name=\"conversation\"), # MessagesPlaceholder 객체 생성(대화 내용 삽입)\n",
    "        (\"human\", \"지금까지의 대화를 {word_count} 단어로 요약합니다.\"), # human 메시지\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c46218",
   "metadata": {},
   "source": [
    "##### - MessagesPlaceholder 실행방법\n",
    "\n",
    "- 방법 1. format 메서드로 LLM 호출(수동 렌더링)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752aca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_chat_prompt = chat_prompt.format(\n",
    "    word_count=5, # 단어 수 지정\n",
    "    conversation=[ # MessagesPlaceholder에 들어갈 대화 내용 지정\n",
    "        (\"human\", \"안녕하세요! 저는 오늘 새로 입사한 테디 입니다. 만나서 반갑습니다.\"),\n",
    "        (\"ai\", \"반가워요! 앞으로 잘 부탁 드립니다.\"),\n",
    "    ], \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba52ac76",
   "metadata": {},
   "source": [
    "- 방법 2. chain 생성 후 invoke 메서드 사용(자동 렌더링)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8427e2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain 생성\n",
    "chain = chat_prompt | llm | StrOutputParser()\n",
    "\n",
    "# chain 실행 및 결과확인\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"word_count\": 5, # 단어 수 지정\n",
    "        \"conversation\": [ # MessagesPlaceholder에 들어갈 대화 내용 지정\n",
    "            (\n",
    "                \"human\",\n",
    "                \"안녕하세요! 저는 오늘 새로 입사한 테디 입니다. 만나서 반갑습니다.\",\n",
    "            ),\n",
    "            (\"ai\", \"반가워요! 앞으로 잘 부탁 드립니다.\"),\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296297b2",
   "metadata": {},
   "source": [
    "#### 4. FewShotPromptTemplate\n",
    "\n",
    "##### - 퓨샷 기법(FewShotPromptTemplate)\n",
    ": 예제(example)를 프롬프트 앞에 포함하여 모델이 특정 질문-답변을 할 수 있도록 하는 프롬프트 템플릿\n",
    "\n",
    " - 제로샷(zero-shot) : 예제 없음\n",
    "\n",
    " - 원샷(one-shot) : 하나의 예제\n",
    "\n",
    " - 퓨샷(few-shot) : 여러 개의 예제 → FewShotPromptTemplate에서는 퓨샷을 대부분 사용함\n",
    "\n",
    "##### - FewShotPromptTemplate 객체\n",
    " - `examples` : 예제 데이터 목록\n",
    " \n",
    " - `example_prompt` : 예제 데이터를 어떻게 LLM이 읽을 수 있는 형태로 변환할 것인지 정하는 규칙\n",
    "\n",
    " - `suffix` : 실제 LLM에게 할 질문\n",
    "\n",
    " - `input_variables` : 입력받아야 할 변수 목록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54df4e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "examples = [ # 예제 질문(key)-답변(value)(list of dict 형태)\n",
    "    {\n",
    "        \"question\": \"스티브 잡스와 아인슈타인 중 누가 더 오래 살았나요?\",\n",
    "        \"answer\": \"\"\"이 질문에 추가 질문이 필요한가요: 예.\n",
    "추가 질문: 스티브 잡스는 몇 살에 사망했나요?\n",
    "중간 답변: 스티브 잡스는 56세에 사망했습니다.\n",
    "추가 질문: 아인슈타인은 몇 살에 사망했나요?\n",
    "중간 답변: 아인슈타인은 76세에 사망했습니다.\n",
    "최종 답변은: 아인슈타인\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"네이버의 창립자는 언제 태어났나요?\",\n",
    "        \"answer\": \"\"\"이 질문에 추가 질문이 필요한가요: 예.\n",
    "추가 질문: 네이버의 창립자는 누구인가요?\n",
    "중간 답변: 네이버는 이해진에 의해 창립되었습니다.\n",
    "추가 질문: 이해진은 언제 태어났나요?\n",
    "중간 답변: 이해진은 1967년 6월 22일에 태어났습니다.\n",
    "최종 답변은: 1967년 6월 22일\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"율곡 이이의 어머니가 태어난 해의 통치하던 왕은 누구인가요?\",\n",
    "        \"answer\": \"\"\"이 질문에 추가 질문이 필요한가요: 예.\n",
    "추가 질문: 율곡 이이의 어머니는 누구인가요?\n",
    "중간 답변: 율곡 이이의 어머니는 신사임당입니다.\n",
    "추가 질문: 신사임당은 언제 태어났나요?\n",
    "중간 답변: 신사임당은 1504년에 태어났습니다.\n",
    "추가 질문: 1504년에 조선을 통치한 왕은 누구인가요?\n",
    "중간 답변: 1504년에 조선을 통치한 왕은 연산군입니다.\n",
    "최종 답변은: 연산군\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"올드보이와 기생충의 감독이 같은 나라 출신인가요?\",\n",
    "        \"answer\": \"\"\"이 질문에 추가 질문이 필요한가요: 예.\n",
    "추가 질문: 올드보이의 감독은 누구인가요?\n",
    "중간 답변: 올드보이의 감독은 박찬욱입니다.\n",
    "추가 질문: 박찬욱은 어느 나라 출신인가요?\n",
    "중간 답변: 박찬욱은 대한민국 출신입니다.\n",
    "추가 질문: 기생충의 감독은 누구인가요?\n",
    "중간 답변: 기생충의 감독은 봉준호입니다.\n",
    "추가 질문: 봉준호는 어느 나라 출신인가요?\n",
    "중간 답변: 봉준호는 대한민국 출신입니다.\n",
    "최종 답변은: 예\n",
    "\"\"\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406e91a7",
   "metadata": {},
   "source": [
    "- 예제 렌더링 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50e0560",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = PromptTemplate.from_template( # PromptTemplate 객체 생성\n",
    "    \"Question:\\n{question}\\nAnswer:\\n{answer}\"\n",
    ")\n",
    "\n",
    "example_prompt.format(**examples[0]) # 프롬프트 생성\n",
    "# 딕셔너리 언패킹(**)를 사용하여 examples[0]의 question, answer 값을 각각 치환\n",
    "# example_prompt.format(\n",
    "#     question=examples[0][\"question\"],\n",
    "#     answer=examples[0][\"answer\"]\n",
    "# ) 과 동일"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670be5bf",
   "metadata": {},
   "source": [
    "##### - FewShotPromptTemplate 실행 방법\n",
    "\n",
    " - 방법 1. format()으로 프롬프트 문자열 생성(수동 렌더링)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bbfc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = FewShotPromptTemplate( # FewShotPromptTemplate 객체 생성\n",
    "    examples=examples, \n",
    "    example_prompt=example_prompt, # 각 예제에 대해 내부적으로 format(**example)을 실행\n",
    "    suffix=\"Question:\\n{question}\\nAnswer:\", #실제 질문-답변 템플릿\n",
    "    input_variables=[\"question\"], # 입력받을 변수 지정\n",
    ")\n",
    "\n",
    "question = \"Google이 창립된 연도에 Bill Gates의 나이는 몇 살인가요?\"\n",
    "final_prompt = prompt.format(question=question) # format 메서드로 프롬프트 생성\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_teddynote.prompts import stream_response\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "# 결과 출력\n",
    "answer = llm.stream(final_prompt)\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75428e4f",
   "metadata": {},
   "source": [
    " - 방법 2. chain 생성 후 invoke로 실행(자동 렌더링)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a446be1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain 생성\n",
    "chain = prompt | llm | StrOutputParser() # 프롬프트 렌더링 + LLM 호출 + 출력 파싱\n",
    "\n",
    "# 결과 출력\n",
    "answer = chain.stream(\n",
    "    {\"question\": \"Google이 창립된 연도에 Bill Gates의 나이는 몇 살인가요?\"}\n",
    ")\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf083aae",
   "metadata": {},
   "source": [
    "#### 5. 예제 선택기\n",
    "\n",
    "##### - SemanticSimilarityExampleSelector\n",
    ": 질문과 유사한 예시를 임베딩 기반 유사도 검색 후 example 목록에서 찾아 상위 k개를 선택\n",
    "\n",
    "→ 다양성이 부족하여 비슷한 예제로 중복될 수 있음\n",
    "\n",
    "→ 사용자 지정 임베딩 방법과 코사인 유사도 기반 계산\n",
    "\n",
    "##### - SemanticSimilarityExampleSelector 객체\n",
    "\n",
    " - `examples` : 예제 데이터 목록\n",
    "\n",
    " - `embedding` : 텍스트를 벡터로 변환하는 임베딩 모델\n",
    "\n",
    " - `vectorstore_cls` : 임베딩 벡터 저장 및 유사도 검색하는 VectorStore(저장소, DB)\n",
    "\n",
    " - `k` : 선택할 예제 개수(상위 k개)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4b563c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.example_selectors import (MaxMarginalRelevanceExampleSelector,SemanticSimilarityExampleSelector)\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "chroma = Chroma(\"example_selector\", OpenAIEmbeddings())\n",
    "\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    examples,\n",
    "    OpenAIEmbeddings(), # OpenAI text embedding 모델 사용\n",
    "    Chroma, # Vector DB\n",
    "    k=1, # 상위 1개\n",
    ")\n",
    "\n",
    "question = \"Google이 창립된 연도에 Bill Gates의 나이는 몇 살인가요?\"\n",
    "\n",
    "# 질문과 예제간의 SemanticSimilarityExampleSelector를 이용한 유사도 계산\n",
    "selected_examples = example_selector.select_examples({\"question\": question})\n",
    "\n",
    "# 어떤 예시가 선택되었는지 출력\n",
    "print(f\"입력에 가장 유사한 예시:\\n{question}\\n\")\n",
    "for example in selected_examples:\n",
    "    print(f'question:\\n{example[\"question\"]}')\n",
    "    print(f'answer:\\n{example[\"answer\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdf340b",
   "metadata": {},
   "source": [
    "`ExampleSelector` 를 사용하여 `FewShotPromptTemplate` 생성 → 프롬프트에 포함하여 최종 질문-답변 형식의 템플릿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6ab3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선택된 예시로 FewShotPromptTemplate 객체 생성\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"Question:\\n{question}\\nAnswer:\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "question = \"Google이 창립된 연도에 Bill Gates의 나이는 몇 살인가요?\"\n",
    "example_selector_prompt = prompt.format(question=question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e734e635",
   "metadata": {},
   "source": [
    "##### - MaxMarginalRelevanceExampleSelector\n",
    ": 유사도과 예시의 다양성까지 고려하여 example 목록에서 찾아 선택\n",
    "\n",
    "→ 사용자에게 다양하고 관련성있는 정보를 제공하여 커버리지가 좋아짐\n",
    "\n",
    "1. 관련성(relavance) : 사용자가 입력한 검색어, 주제, 문서와 잘 맞는지를 평가하는 기준\n",
    "\n",
    "2. 다양성(diversity) : 선택된 예제와 새로운 예제 간의 유사성 계산\n",
    "\n",
    "MMR은 질문과의 유사도와 이미 선택된 예제들과의 중복을 동시에 고려하여, 다음 식과 같이 예제를 선택한다.\n",
    "\n",
    "$$\n",
    "\\text{MMR}\n",
    "=\n",
    "\\arg\\max_{d_i \\in R \\setminus S}\n",
    "\\left[\n",
    "\\lambda \\cdot \\text{Sim}(d_i, Q)\n",
    "-\n",
    "(1 - \\lambda) \\cdot \\max_{d_j \\in S} \\text{Sim}(d_i, d_j)\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "- $R$ : 전체 후보 예제 집합 \n",
    "\n",
    "- $S$ : 이미 선택된 예제 집합  \n",
    "\n",
    "- $Q$ : 입력 질문  \n",
    "\n",
    "- $\\text{Sim}(\\cdot)$ : 코사인 유사도  \n",
    "\n",
    "- $\\lambda$ : 유사도와 다양성 간의 균형 계수, 값이 클수록 관련성 중시, 값이 작을수록 다양성 중시"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7738f01c",
   "metadata": {},
   "source": [
    "#### 6. FewShotChatMessagePromptTemplate\n",
    "\n",
    "##### - FewShotChatMessagePromptTemplate\n",
    " : FewShotPromptTemplate과 ChatMessage를 결합하여 대화형 프롬프트에서 few-shot을 메시지 단위로 구성하기 위한 메시지 프롬프트 템플릿\n",
    "\n",
    "##### - FewShotChatMessagePromptTemplate 객체\n",
    " - `examples` : 예제 데이터 목록\n",
    "\n",
    " - `example_prompt` : 예제 데이터를 어떻게 LLM이 읽을 수 있는 형태로 변환할 것인지 정하는 규칙"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef78af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [ # 예제 질문(key)-답변(value)(list of dict 형태)\n",
    "    {\n",
    "        \"instruction\": \"당신은 회의록 작성 전문가 입니다. 주어진 정보를 바탕으로 회의록을 작성해 주세요\",\n",
    "        \"input\": \"2023년 12월 25일, XYZ 회사의 마케팅 전략 회의가 오후 3시에 시작되었다. 회의에는 마케팅 팀장인 김수진, 디지털 마케팅 담당자인 박지민, 소셜 미디어 관리자인 이준호가 참석했다. 회의의 주요 목적은 2024년 상반기 마케팅 전략을 수립하고, 새로운 소셜 미디어 캠페인에 대한 아이디어를 논의하는 것이었다. 팀장인 김수진은 최근 시장 동향에 대한 간략한 개요를 제공했으며, 이어서 각 팀원이 자신의 분야에서의 전략적 아이디어를 발표했다.\",\n",
    "        \"answer\": \"\"\"\n",
    "회의록: XYZ 회사 마케팅 전략 회의\n",
    "일시: 2023년 12월 25일\n",
    "장소: XYZ 회사 회의실\n",
    "참석자: 김수진 (마케팅 팀장), 박지민 (디지털 마케팅 담당자), 이준호 (소셜 미디어 관리자)\n",
    "\n",
    "1. 개회\n",
    "   - 회의는 김수진 팀장의 개회사로 시작됨.\n",
    "   - 회의의 목적은 2024년 상반기 마케팅 전략 수립 및 새로운 소셜 미디어 캠페인 아이디어 논의.\n",
    "\n",
    "2. 시장 동향 개요 (김수진)\n",
    "   - 김수진 팀장은 최근 시장 동향에 대한 분석을 제시.\n",
    "   - 소비자 행동 변화와 경쟁사 전략에 대한 통찰 공유.\n",
    "\n",
    "3. 디지털 마케팅 전략 (박지민)\n",
    "   - 박지민은 디지털 마케팅 전략에 대해 발표.\n",
    "   - 온라인 광고와 SEO 최적화 방안에 중점을 둠.\n",
    "\n",
    "4. 소셜 미디어 캠페인 (이준호)\n",
    "   - 이준호는 새로운 소셜 미디어 캠페인에 대한 아이디어를 제안.\n",
    "   - 인플루언서 마케팅과 콘텐츠 전략에 대한 계획을 설명함.\n",
    "\n",
    "5. 종합 논의\n",
    "   - 팀원들 간의 아이디어 공유 및 토론.\n",
    "   - 각 전략에 대한 예산 및 자원 배분에 대해 논의.\n",
    "\n",
    "6. 마무리\n",
    "   - 다음 회의 날짜 및 시간 확정.\n",
    "   - 회의록 정리 및 배포는 박지민 담당.\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"당신은 요약 전문가 입니다. 다음 주어진 정보를 바탕으로 내용을 요약해 주세요\",\n",
    "        \"input\": \"이 문서는 '지속 가능한 도시 개발을 위한 전략'에 대한 20페이지 분량의 보고서입니다. 보고서는 지속 가능한 도시 개발의 중요성, 현재 도시화의 문제점, 그리고 도시 개발을 지속 가능하게 만들기 위한 다양한 전략을 포괄적으로 다루고 있습니다. 이 보고서는 또한 성공적인 지속 가능한 도시 개발 사례를 여러 국가에서 소개하고, 이러한 사례들을 통해 얻은 교훈을 요약하고 있습니다.\",\n",
    "        \"answer\": \"\"\"\n",
    "문서 요약: 지속 가능한 도시 개발을 위한 전략 보고서\n",
    "\n",
    "- 중요성: 지속 가능한 도시 개발이 필수적인 이유와 그에 따른 사회적, 경제적, 환경적 이익을 강조.\n",
    "- 현 문제점: 현재의 도시화 과정에서 발생하는 주요 문제점들, 예를 들어 환경 오염, 자원 고갈, 불평등 증가 등을 분석.\n",
    "- 전략: 지속 가능한 도시 개발을 달성하기 위한 다양한 전략 제시. 이에는 친환경 건축, 대중교통 개선, 에너지 효율성 증대, 지역사회 참여 강화 등이 포함됨.\n",
    "- 사례 연구: 전 세계 여러 도시의 성공적인 지속 가능한 개발 사례를 소개. 예를 들어, 덴마크의 코펜하겐, 일본의 요코하마 등의 사례를 통해 실현 가능한 전략들을 설명.\n",
    "- 교훈: 이러한 사례들에서 얻은 주요 교훈을 요약. 강조된 교훈에는 다각적 접근의 중요성, 지역사회와의 협력, 장기적 계획의 필요성 등이 포함됨.\n",
    "\n",
    "이 보고서는 지속 가능한 도시 개발이 어떻게 현실적이고 효과적인 형태로 이루어질 수 있는지에 대한 심도 있는 분석을 제공합니다.\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"당신은 문장 교정 전문가 입니다. 다음 주어진 문장을 교정해 주세요\",\n",
    "        \"input\": \"우리 회사는 새로운 마케팅 전략을 도입하려고 한다. 이를 통해 고객과의 소통이 더 효과적이 될 것이다.\",\n",
    "        \"answer\": \"본 회사는 새로운 마케팅 전략을 도입함으로써, 고객과의 소통을 보다 효과적으로 개선할 수 있을 것으로 기대된다.\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa6ff83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_core.example_selectors import (\n",
    "    SemanticSimilarityExampleSelector,\n",
    ")\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "chroma = Chroma(\"fewshot_chat\", OpenAIEmbeddings()) # VectorDB 생성\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages( # 프롬프트 정의\n",
    "    [ \n",
    "        (\"human\", \"{instruction}:\\n{input}\"),\n",
    "        (\"ai\", \"{answer}\"),\n",
    "    ]\n",
    ") # [HumanMessage, AIMessage] 리스트 형태로 구성\n",
    "\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples( \n",
    "    examples, # 예시 목록\n",
    "    OpenAIEmbeddings(), # 임베딩\n",
    "    chroma, # VectorDB\n",
    "    k=1, # 상위 1개\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate( \n",
    "    example_selector=example_selector, # 예시 선택기(가장 유사한 예시 1개 선택)\n",
    "    example_prompt=example_prompt, # 예시 프롬프트\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c0edff",
   "metadata": {},
   "source": [
    "##### - FewShotPromptTemplate과 FewShotChatMessagePromptTemplate의 차이\n",
    "\n",
    "- FewShotPromptTemplate : 문자열 기반 프롬프트 \n",
    "\n",
    "- FewShotChatMessagePromptTemplate : Chat모델에서 메시지(role)단위를 유지\n",
    "\n",
    "서로 분리된 구조를 지님"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784340ec",
   "metadata": {},
   "source": [
    "#### 7. CustomExampleSelector\n",
    "\n",
    "##### - CustomExampleSelector\n",
    ": 사용자가 직접 정의한 규칙으로 입력과 적절한 예제를 고르는 예제 선택기\n",
    "\n",
    "\n",
    "##### - CustomExampleSelector 객체\n",
    "\n",
    " - `examples` : 예제 데이터 목록\n",
    "\n",
    " - `embedding` : 텍스트를 벡터로 변환하는 임베딩 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7cb07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.prompts import CustomExampleSelector\n",
    "\n",
    "# 커스텀 예제 선택기 생성\n",
    "custom_selector = CustomExampleSelector(examples, OpenAIEmbeddings())\n",
    "\n",
    "# 커스텀 예제 선택기를 사용했을 때 결과\n",
    "custom_selector.select_examples({\"instruction\": \"다음 문장을 회의록 작성해 주세요\"})\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{instruction}:\\n{input}\"),\n",
    "        (\"ai\", \"{answer}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "custom_fewshot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_selector=custom_selector,  # 커스텀 예제 선택기 사용\n",
    "    example_prompt=example_prompt,  # 예제 프롬프트 사용\n",
    ")\n",
    "\n",
    "custom_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant.\",\n",
    "        ),\n",
    "        custom_fewshot_prompt,\n",
    "        (\"human\", \"{instruction}\\n{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# chain 을 생성합니다.\n",
    "chain = custom_prompt | llm\n",
    "\n",
    "question = {\n",
    "    \"instruction\": \"회의록을 작성해 주세요\",\n",
    "    \"input\": \"2023년 12월 26일, ABC 기술 회사의 제품 개발 팀은 새로운 모바일 애플리케이션 프로젝트에 대한 주간 진행 상황 회의를 가졌다. 이 회의에는 프로젝트 매니저인 최현수, 주요 개발자인 황지연, UI/UX 디자이너인 김태영이 참석했다. 회의의 주요 목적은 프로젝트의 현재 진행 상황을 검토하고, 다가오는 마일스톤에 대한 계획을 수립하는 것이었다. 각 팀원은 자신의 작업 영역에 대한 업데이트를 제공했고, 팀은 다음 주까지의 목표를 설정했다.\",\n",
    "}\n",
    "stream_response(chain.stream(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3806306f",
   "metadata": {},
   "source": [
    "#### 8. 출력 파서(Output Parser)\n",
    "\n",
    "##### - 출력 파서(Output Parser)\n",
    ": LLM 모델의 출력값을 구조화된 형식으로 변환하고 원하는 정보를 추출할 수 있는 요소 \n",
    "→ JSON 형식으로 구조화된 답변을 받을 수 있음(key-value 형태)\n",
    "\n",
    "##### - 출력 파서의 특징\n",
    " 1. 다양성 : 다양한 종류의 출력 파서 제공\n",
    "\n",
    " 2. 스트리밍 지원 : 실시간 데이터 처리 가능\n",
    "\n",
    " 3. 확장성 : 확장 가능한 인터페이스 제공\n",
    "\n",
    "##### - 출력 파서의 장점\n",
    "\n",
    " 1. 구조화 : 출력을 구조화된 데이터로 변환하여 체계적인 정보 관리\n",
    "\n",
    " 2. 일관성 : 일관된 출력 형식\n",
    "\n",
    " 3. 유연성 : JSON, 딕셔너리, 리스트 등 다양한 출력 형식 변환 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b8a991",
   "metadata": {},
   "source": [
    "#### 9. PydanticOutPutParser\n",
    "\n",
    "##### - Pydantic 모델\n",
    " : 데이터의 구조(필드), 타입, 제약조건을 정의한 설계도(schema)\n",
    "\n",
    "##### - Pydantic 객체\n",
    " : Pydantic 모델을 기준으로 실제 값이 채워진 실제 데이터\n",
    "\n",
    "##### - PydanticOutPutParser \n",
    ": LLM의 텍스트 출력을 특정 Pydantic 데이터 모델(schema)에 맞게 구조화된 객체로 변환\n",
    "\n",
    " - Pydantic : 데이터 구조 정의 타입 검증 및 변환 자동 수행하는 라이브러리\n",
    " → 원하는 정보만 정확한 구조, 타입으로 출력하기 위함 \n",
    "\n",
    " - 스키마(schema) : 데이터가 가져야 할 구조, 규칙을 정의\n",
    "\n",
    "##### - PydanticOutPutParser 주요 메서드\n",
    " - `get_format_instructions()` : LLM이 출력해야 할 정보 형식 정의 ex) 데이터 필드\n",
    " → Pydantic 모델에 맞는 출력을 유도\n",
    "\n",
    " - `parse()` : LLM 출력에서 정해진 규칙(schema)을 기준으로 의미 있는 값을 뽑아 Pydantic 모델에 넣고, 스키마 검증 후 객체로 변환\n",
    "\n",
    "##### - PydanticOutPutParser 객체\n",
    " - `pydantic_object` : LLM 출력이 따라야 할 데이터 모델(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cddf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic을 사용한 출력 파싱 예제\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Person(BaseModel): # 이때 Person 클래스는 Pydantic 모델\n",
    "    name: str\n",
    "    age: int\n",
    "\n",
    "person = Person(name=\"테디\", age=20) # Person 객체는 Pydantic 객체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bad8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실시간 출력을 위한 import\n",
    "from langchain_teddynote.messages import stream_response\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field # Pydantic 모델 정의에 사용\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4.1-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598d44b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_conversation = \"\"\"From: 김철수 (chulsoo.kim@bikecorporation.me) \n",
    "To: 이은채 (eunchae@teddyinternational.me)\n",
    "Subject: \"ZENESIS\" 자전거 유통 협력 및 미팅 일정 제안\n",
    "\n",
    "안녕하세요, 이은채 대리님,\n",
    "\n",
    "저는 바이크코퍼레이션의 김철수 상무입니다. 최근 보도자료를 통해 귀사의 신규 자전거 \"ZENESIS\"에 대해 알게 되었습니다. 바이크코퍼레이션은 자전거 제조 및 유통 분야에서 혁신과 품질을 선도하는 기업으로, 이 분야에서의 장기적인 경험과 전문성을 가지고 있습니다.\n",
    "\n",
    "ZENESIS 모델에 대한 상세한 브로슈어를 요청드립니다. 특히 기술 사양, 배터리 성능, 그리고 디자인 측면에 대한 정보가 필요합니다. 이를 통해 저희가 제안할 유통 전략과 마케팅 계획을 보다 구체화할 수 있을 것입니다.\n",
    "\n",
    "또한, 협력 가능성을 더 깊이 논의하기 위해 다음 주 화요일(1월 15일) 오전 10시에 미팅을 제안합니다. 귀사 사무실에서 만나 이야기를 나눌 수 있을까요?\n",
    "\n",
    "감사합니다.\n",
    "\n",
    "김철수\n",
    "상무이사\n",
    "바이크코퍼레이션\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610a0294",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailSummary(BaseModel): # Pydantic 모델 정의\n",
    "    # 각 description은 필드에 대한 설명을 제공(LLM이 해당 설명을 보고 정보 추출)\n",
    "    person: str = Field(description=\"메일을 보낸 사람\")\n",
    "    email: str = Field(description=\"메일을 보낸 사람의 이메일 주소\")\n",
    "    subject: str = Field(description=\"메일 제목\")\n",
    "    summary: str = Field(description=\"메일 본문을 요약한 텍스트\")\n",
    "    date: str = Field(description=\"메일 본문에 언급된 미팅 날짜와 시간\")\n",
    "\n",
    "\n",
    "# PydanticOutputParser 생성\n",
    "parser = PydanticOutputParser(pydantic_object=EmailSummary)\n",
    "\n",
    "parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bacab32",
   "metadata": {},
   "source": [
    "프롬프트 정의\n",
    "\n",
    "1. `question`: 유저의 질문을 받음\n",
    "\n",
    "2. `email_conversation`: 이메일 본문의 내용을 입력\n",
    "\n",
    "3. `format`: 형식을 지정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e56db09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt 템플릿 생성\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are a helpful assistant. Please answer the following questions in KOREAN.\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "EMAIL CONVERSATION:\n",
    "{email_conversation}\n",
    "\n",
    "FORMAT:\n",
    "{format}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438f2058",
   "metadata": {},
   "source": [
    "##### - LLM 출력 파싱 방법\n",
    "\n",
    "- 방법 1. LLM 출력 결과로 (수동 파싱)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bcdf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format에 PydanticOutputParser의 부분 포맷팅(partial) 추가\n",
    "prompt = prompt.partial(format=parser.get_format_instructions())\n",
    "\n",
    "# chain 생성\n",
    "chain = prompt | llm\n",
    "\n",
    "# chain 실행 및 결과 출력\n",
    "response = chain.stream(\n",
    "    {\n",
    "        \"email_conversation\": email_conversation,\n",
    "        \"question\": \"이메일 내용중 주요 내용을 추출해 주세요.\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# JSON 형태로 출력\n",
    "output = stream_response(response, return_output=True) # True면 스트리밍 + 문자열 False면 스트리밍만 반환\n",
    "\n",
    "# PydanticOutputParser를 사용하여 결과 파싱\n",
    "structured_output = parser.parse(output) # LLM이 출력한 문자열 output을 Pydantic 객체로 파싱"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d17003e",
   "metadata": {},
   "source": [
    "- 방법 2. Chain에 Parser를 구성하여 (자동 파싱)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00496f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력 파서를 추가하여 전체 체인 재구성\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "# chain 실행 및 결과 출력\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"email_conversation\": email_conversation,\n",
    "        \"question\": \"이메일 내용중 주요 내용을 추출해 주세요.\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# EmailSummary 객체 형태로 출력\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d53f29",
   "metadata": {},
   "source": [
    "#### 10. with_structured_output() 바인딩\n",
    "\n",
    ": `with_structured_output(Pydantic)`을 사용하여 출력을 Pydantic 객체 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a62e696",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_structered = ChatOpenAI(\n",
    "    temperature=0, model_name=\"gpt-4.1-mini\"\n",
    ").with_structured_output(EmailSummary) \n",
    "\n",
    "# invoke() 함수를 호출하여 결과를 출력합니다.\n",
    "answer = llm_with_structered.invoke(email_conversation) # 출력 결과를 바로 Pydantic 객체로 반환\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8b5596",
   "metadata": {},
   "source": [
    "##### - PydanticOutputParser과 with_structured_output()의 차이\n",
    " - `PydanticOutputParser` : LLM 응답 생성 후 출력한 결과를 가지고 Pydantic 객체로 변환\n",
    "\n",
    " - `with_structured_output()` : LLM 응답 생성 과정에서 Pydantic 객체로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675a5d22",
   "metadata": {},
   "source": [
    "\n",
    "| 구분 | PydanticOutputParser       | with_structured_output()    |\n",
    "|------------|---------------------|---------------|\n",
    "|  적용 시점   | 생성 후 단계(후처리)        | 생성 단계(전처리)          |\n",
    "|  어디에 붙나   | 모델    | 체인        |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330880f6",
   "metadata": {},
   "source": [
    "#### 11. 쉼표 구분된 리스트 출력 파서\n",
    "\n",
    "##### - 쉼표 구분된 리스트 출력 파서(CommaSeparatedListOutputParser)\n",
    " : 쉼표(,)로 구분된 LLM의 출력 결과인 문자열을 리스트로 변환하는 출력 파서\n",
    "\n",
    " ex) 서울, 부산, 경기도 → [\"서울\", \"부산\", \"경기도\"]\n",
    "\n",
    "\n",
    "##### - CommaSeparatedListOutputParser 객체\n",
    "- `get_format_instructions()` : LLM이 출력해야 할 정보 형식 정의 ex) 데이터 필드\n",
    " → Pydantic 모델에 맞는 출력을 유도\n",
    "\n",
    " - `parse()` : LLM 출력에서 정해진 규칙(schema)을 기준으로 의미 있는 값을 뽑아 Pydantic 모델에 넣고, 스키마 검증 후 객체로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4423a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 콤마로 구분된 리스트 출력 파서 변환\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "# 출력 형식 지침 가져오기\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "# 프롬프트 템플릿 설정\n",
    "prompt = PromptTemplate(\n",
    "    # 주제에 대한 다섯 가지를 나열하라는 템플릿\n",
    "    template=\"List five {subject}.\\n{format_instructions}\",\n",
    "    input_variables=[\"subject\"],\n",
    "    # 부분 변수로 형식 지침 사용\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(temperature=0)\n",
    "\n",
    "# chain 생성\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "# list 반환\n",
    "chain.invoke({\"subject\": \"대한민국 관광명소\"})\n",
    "\n",
    "for s in chain.stream({\"subject\": \"대한민국 관광명소\"}):\n",
    "    print(s)  # 스트림의 내용을 출력, 활용성 떨어짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97767c3c",
   "metadata": {},
   "source": [
    "#### 12. 구조화된 출력 파서\n",
    "\n",
    "##### - 구조화된 출력 파서(StructuredOutputParser)\n",
    " : JSON 형식이 과도하거나 불안정한 상황에서 최소한의 key-value 구조를 출력하는 출력 파서\n",
    "  \n",
    "  → GPT, Claude 모델 보다 인텔리전스가 낮은 로컬 모델에 사용, JSON/Pydantic보다 가벼워 간단한 경우 사용함\n",
    "\n",
    "##### - StructuredOutputParser 객체\n",
    ": LLM의 출력을 사전에 정의한 필드(schema)에 맞춰 딕셔너리 형태로 변환하는 객체\n",
    "\n",
    "- `response_schemas` : LLM 출력에 포함되어야 할 필드 목록\n",
    "\n",
    "##### - ResponseSchema 객체\n",
    ": LLM 응답에 포함되어야 할 필드의 이름, 의미를 정의\n",
    "\n",
    "- `name` : 출력 결과에서 사용할 key 이름\n",
    "\n",
    "- `description` : LLM에게 해당 필드에 대한 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98b4110",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM 출력에 반드시 포함되어야 할 필드 목록 정의\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"answer\", description=\"사용자의 질문에 대한 답변\"),\n",
    "    ResponseSchema(\n",
    "        name=\"source\",\n",
    "        description=\"사용자의 질문에 답하기 위해 사용된 `출처`, `웹사이트주소` 이여야 합니다.\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "# 응답을 구조화한 출력 파서 생성\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "# 출력 형식 지시사항 파싱\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "prompt = PromptTemplate(\n",
    "    template=\"answer the users question as best as possible.\\n{format_instructions}\\n{question}\",\n",
    "    input_variables=[\"question\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ") # 프롬프트 템플릿 생성\n",
    "\n",
    "model = ChatOpenAI(temperature=0)\n",
    "chain = prompt | model | output_parser # chain 생성\n",
    "\n",
    "# dict 반환\n",
    "chain.invoke({\"question\": \"대한민국의 수도는 어디인가요?\"})\n",
    "\n",
    "for s in chain.stream({\"question\": \"세종대왕의 업적은 무엇인가요?\"}):\n",
    "    # 스트리밍 출력\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca01934",
   "metadata": {},
   "source": [
    "#### 13. JSON 형식 출력 파서\n",
    "\n",
    "##### - JSON 형식 출력 파서(JsonOutputParser)\n",
    ": LLM의 출력을 JSON 형식의 데이터를 추출하여 구조화된 Python 딕셔너리(dict)로 변환하는 출력 파서\n",
    "→ 용량이 작은 모델에서 JsonOutputParser를 사용할 경우 오류가 발생할 수 있음\n",
    "\n",
    "##### - JsonOutputParser 객체\n",
    "\n",
    " - `get_format_instructions()` : LLM이 출력해야 할 정보 형식 정의 ex) 데이터 필드\n",
    "  → Pydantic 모델에 맞는 출력을 유도\n",
    "\n",
    " - `parse()` : LLM의 출력 텍스트를 Pydantic 모델 기준으로 파싱·검증하여 객체로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e4f0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "model = ChatOpenAI(temperature=0, model_name=\"gpt-4.1-mini\")\n",
    "\n",
    "# Pydantic 모델 정의\n",
    "class Topic(BaseModel):\n",
    "    description: str = Field(description=\"주제에 대한 간결한 설명\")\n",
    "    hashtags: str = Field(description=\"해시태그 형식의 키워드(2개 이상)\")\n",
    "\n",
    "question = \"지구 온난화의 심각성 대해 알려주세요.\"\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=Topic) # JsonOutputParser 생성\n",
    "print(parser.get_format_instructions()) \n",
    "\n",
    "# 프롬프트 템플릿 생성\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 친절한 AI 어시스턴트 입니다. 질문에 간결하게 답변하세요.\"),\n",
    "        (\"user\", \"#Format: {format_instructions}\\n\\n#Question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "prompt = prompt.partial(format_instructions=parser.get_format_instructions()) # ChatPromptTemplate를 수정한 새로운 프롬프트 생성\n",
    "\n",
    "# 체인 구성\n",
    "chain = prompt | model | parser\n",
    "answer = chain.invoke({\"question\": question})\n",
    "\n",
    "type(answer)\n",
    "answer # dict 형태"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d5cbe3",
   "metadata": {},
   "source": [
    "##### - StructuredOutputParser과 JsonOutputParser 차이\n",
    "\n",
    "- `StructuredOutputParser`\n",
    ": 출력 형식 요구가 단순하여 출력 제어가 약한 로컬·소형 모델에서도 안정적으로 파싱 가능\n",
    "\n",
    "- `JsonOutputParser`\n",
    ": JSON 문법을 정확히 지켜야 하며 형식이 조금이라도 깨질 경우 파싱 오류 발생"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af9e1a5",
   "metadata": {},
   "source": [
    "#### 14. Pandas 데이터프레임 출력 파서\n",
    "\n",
    "##### - Pandas 데이터프레임 출력 파서(PandasDataFrameOutputParser)\n",
    " : LLM 출력 결과를 Pandas Dataframe 객체로 변환하는 출력 파서\n",
    "\n",
    "##### - PandasDataFrameOutputParser 객체\n",
    " \n",
    " - `dataframe_columns` : DataFrame에 포함되어야 할 열(column) 목록, None일 경우 임시 컬럼명 및 첫 줄을 열로 판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f229234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "from typing import Any, Dict\n",
    "import pandas as pd\n",
    "from langchain.output_parsers import PandasDataFrameOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "# 출력 목적으로 사용\n",
    "def format_parser_output(parser_output: Dict[str, Any]) -> None:\n",
    "    # 파서 출력 키 순회\n",
    "    for key in parser_output.keys():\n",
    "        # 각 키의 값을 딕셔너리로 변환\n",
    "        parser_output[key] = parser_output[key].to_dict()\n",
    "    return pprint.PrettyPrinter(width=4, compact=True).pprint(parser_output) # 들여쓰기 4칸, 한 줄로 출력\n",
    "\n",
    "df = pd.read_csv(\"./data/titanic.csv\") # 데이터 불러오기\n",
    "df.head()\n",
    "\n",
    "parser = PandasDataFrameOutputParser(dataframe=df)\n",
    "print(parser.get_format_instructions())\n",
    "\n",
    "df_query = \"Age column 을 조회해 주세요.\" # Age 열 조회\n",
    "\n",
    "# 프롬프트 템플릿 생성\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{question}\\n\",\n",
    "    input_variables=[\"question\"],\n",
    "    partial_variables={\n",
    "        \"format_instructions\": parser.get_format_instructions()\n",
    "    },\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser # chain 생성\n",
    "\n",
    "parser_output = chain.invoke({\"question\": df_query})\n",
    "format_parser_output(parser_output)\n",
    "\n",
    "# 행 조회\n",
    "df_query = \"Retrieve the first row.\"\n",
    "\n",
    "# 체인 실행\n",
    "parser_output = chain.invoke({\"question\": df_query})\n",
    "\n",
    "# row 0 ~ 4의 평균 나이 계산\n",
    "df[\"Age\"].head().mean()\n",
    "\n",
    "# Pandas DataFrame 작업 예시, 행의 수를 제한\n",
    "df_query = \"Retrieve the average of the Ages from row 0 to 4.\"\n",
    "\n",
    "# 체인 실행\n",
    "parser_output = chain.invoke({\"question\": df_query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcb5d56",
   "metadata": {},
   "source": [
    "#### 15. 날짜 형식 출력 파서\n",
    "\n",
    "##### - 날짜 형식 출력 파서(DatetimeOutputParser)\n",
    " : LLM의 출력을 datetime 형식으로 변환하는 출력 파서\n",
    "\n",
    "##### - DatetimeOutputParser 객체\n",
    " - `format` : LLM 출력이 따라야 할 날짜/시간 문자열 포맷, None일 경우 자동적으로 날짜 포맷 시도\n",
    "\n",
    "##### - datetime 객체\n",
    " : 날자와 시간을 하나의 구조로 표현하는 자료형, (year, month, day)로 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e192b1",
   "metadata": {},
   "source": [
    "**참고**\n",
    "\n",
    "| 형식 코드 | 설명                | 예시          |\n",
    "|------------|---------------------|---------------|\n",
    "| %Y         | 4자리 연도          | 2024          |\n",
    "| %y         | 2자리 연도          | 24            |\n",
    "| %m         | 2자리 월            | 07            |\n",
    "| %d         | 2자리 일            | 04            |\n",
    "| %H         | 24시간제 시간       | 14            |\n",
    "| %I         | 12시간제 시간       | 02            |\n",
    "| %p         | AM 또는 PM          | PM            |\n",
    "| %M         | 2자리 분            | 45            |\n",
    "| %S         | 2자리 초            | 08            |\n",
    "| %f         | 마이크로초 (6자리)  | 000123        |\n",
    "| %z         | UTC 오프셋          | +0900         |\n",
    "| %Z         | 시간대 이름         | KST           |\n",
    "| %a         | 요일 약어           | Thu           |\n",
    "| %A         | 요일 전체           | Thursday      |\n",
    "| %b         | 월 약어             | Jul           |\n",
    "| %B         | 월 전체             | July          |\n",
    "| %c         | 전체 날짜와 시간     | Thu Jul  4 14:45:08 2024 |\n",
    "| %x         | 전체 날짜           | 07/04/24      |\n",
    "| %X         | 전체 시간           | 14:45:08      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1695548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 날짜 및 시간 출력 파서\n",
    "output_parser = DatetimeOutputParser() # datetime 객체 반환\n",
    "output_parser.format = \"%Y-%m-%d\"\n",
    "\n",
    "# 사용자 질문에 대한 답변 템플릿\n",
    "template = \"\"\"Answer the users question:\\n\\n#Format Instructions: \\n{format_instructions}\\n\\n#Question: \\n{question}\\n\\n#Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    template,\n",
    "    partial_variables={\n",
    "        \"format_instructions\": output_parser.get_format_instructions()\n",
    "    },  # 지침을 템플릿에 적용\n",
    ")\n",
    "\n",
    "# 프롬프트 내용 출력\n",
    "prompt\n",
    "\n",
    "# chain 생성\n",
    "chain = prompt | ChatOpenAI() | output_parser\n",
    "output = chain.invoke({\"question\": \"Google 이 창업한 연도\"})\n",
    "\n",
    "# 문자열 변환\n",
    "output.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d894ac3",
   "metadata": {},
   "source": [
    "#### 16. 열거형 출력 파서\n",
    "\n",
    "##### - 열거형 출력 파서(EnumOutputParser)\n",
    " : LLM 출력을 미리 정의된 Enum 값을 기준으로 문자열을 출력하는 출력 파서 → 출력 데이터의 일관성 유지\n",
    " - Enum : 동등한 레벨에 있는 데이터들을 하나의 구조로 묶어 표현\n",
    "\n",
    "##### - EnumOutputParser 객체\n",
    " - `enum` : LLM 출력이 반드시 일치해야 할 값들의 집합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3595291",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.enum import EnumOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from enum import Enum\n",
    "\n",
    "# 선택가능한 값들을 정의하는 Enum 클래스 생성(LLM의 출력은 반드시 이 값들 중 하나여야 함)\n",
    "class Colors(Enum):\n",
    "    RED = \"빨간색\"\n",
    "    GREEN = \"초록색\"\n",
    "    BLUE = \"파란색\"\n",
    "\n",
    "# EnumOutputParser 생성\n",
    "parser = EnumOutputParser(enum=Colors) # Colors Enum 클래스 값 제외 모두 허용하지 않음, 있는 경우 error 발생\n",
    "\n",
    "# 프롬프트 템플릿 생성\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"다음의 물체는 어떤 색깔인가요?\n",
    "\n",
    "Object: {object}\n",
    "\n",
    "Instructions: {instructions}\"\"\"\n",
    ").partial(instructions=parser.get_format_instructions())\n",
    "\n",
    "# 체인 생성\n",
    "chain = prompt | ChatOpenAI() | parser\n",
    "\n",
    "# 체인 실행\n",
    "response = chain.invoke({\"object\": \"하늘\"})\n",
    "type(response) # Enum 타입 <class 'enum.Enum'>\n",
    "response.value # Enum 값 '파란색'('하늘'에 대한 답변)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
